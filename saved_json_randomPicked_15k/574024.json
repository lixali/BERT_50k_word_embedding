{
 "id": "574024",
 "text": "In mathematics and in signal processing, the Hilbert transform is a specific linear operator that takes a function, of a real variable and produces another function of a real variable . This linear operator is given by convolution with the function 1/(\\pi t) (see ). The Hilbert transform has a particularly simple representation in the frequency domain: It imparts a phase shift of ±90° ( radians) to every frequency component of a function, the sign of the shift depending on the sign of the frequency (see ). The Hilbert transform is important in signal processing, where it is a component of the analytic representation of a real-valued signal . The Hilbert transform was first introduced by David Hilbert in this setting, to solve a special case of the Riemann–Hilbert problem for analytic functions. == Definition == The Hilbert transform of can be thought of as the convolution of with the function , known as the Cauchy kernel. Because is not integrable across , the integral defining the convolution does not always converge. Instead, the Hilbert transform is defined using the Cauchy principal value (denoted here by ). Explicitly, the Hilbert transform of a function (or signal) is given by \\operatorname{H}(u)(t) = \\frac{1}{\\pi}\\, \\operatorname{p.v.} \\int_{-\\infty}^{+\\infty} \\frac{u(\\tau)}{t - \\tau}\\;\\mathrm{d}\\tau , provided this integral exists as a principal value. This is precisely the convolution of with the tempered distribution .due to ; see . Alternatively, by changing variables, the principal value integral can be written explicitly as \\operatorname{H}(u)(t) = -\\frac{1}{\\,\\pi\\,}\\,\\lim_{\\varepsilon \\to 0} \\, \\int_\\varepsilon^\\infty \\frac{\\,u(t + \\tau) - u(t - \\tau)\\,}{\\tau} \\;\\mathrm{d}\\tau~ . When the Hilbert transform is applied twice in succession to a function , the result is negative : \\operatorname{H}\\bigl(\\operatorname{H}(u)\\bigr)(t) = -u(t) , provided the integrals defining both iterations converge in a suitable sense. In particular, the inverse transform is . This fact can most easily be seen by considering the effect of the Hilbert transform on the Fourier transform of (see , below). For an analytic function in the upper half-plane, the Hilbert transform describes the relationship between the real part and the imaginary part of the boundary values. That is, if is analytic in the upper half complex plane , and , then up to an additive constant, provided this Hilbert transform exists. ===Notation=== In signal processing the Hilbert transform of is commonly denoted by \\hat{u}(t) .e.g., However, in mathematics, this notation is already extensively used to denote the Fourier transform of .e.g., Occasionally, the Hilbert transform may be denoted by \\tilde{u}(t) . Furthermore, many sources define the Hilbert transform as the negative of the one defined here.e.g., == History == The Hilbert transform arose in Hilbert's 1905 work on a problem Riemann posed concerning analytic functions, which has come to be known as the Riemann–Hilbert problem. Hilbert's work was mainly concerned with the Hilbert transform for functions defined on the circle. Some of his earlier work related to the Discrete Hilbert Transform dates back to lectures he gave in Göttingen. The results were later published by Hermann Weyl in his dissertation. Schur improved Hilbert's results about the discrete Hilbert transform and extended them to the integral case. These results were restricted to the spaces and . In 1928, Marcel Riesz proved that the Hilbert transform can be defined for u in L^p(\\mathbb{R}) (Lp space) for , that the Hilbert transform is a bounded operator on L^p(\\mathbb{R}) for , and that similar results hold for the Hilbert transform on the circle as well as the discrete Hilbert transform. The Hilbert transform was a motivating example for Antoni Zygmund and Alberto Calderón during their study of singular integrals. Their investigations have played a fundamental role in modern harmonic analysis. Various generalizations of the Hilbert transform, such as the bilinear and trilinear Hilbert transforms are still active areas of research today. == Relationship with the Fourier transform == The Hilbert transform is a multiplier operator. The multiplier of is , where is the signum function. Therefore: \\mathcal{F}\\bigl(\\operatorname{H}(u)\\bigr)(\\omega) = -i \\sgn(\\omega) \\cdot \\mathcal{F}(u)(\\omega) , where \\mathcal{F} denotes the Fourier transform. Since , it follows that this result applies to the three common definitions of \\mathcal{F}. By Euler's formula, \\sigma_\\operatorname{H}(\\omega) = \\begin{cases} ~~i = e^{+\\frac{i\\pi}{2}}, & \\text{for } \\omega < 0,\\\\\\ ~~ 0, & \\text{for } \\omega = 0,\\\\\\ -i = e^{-\\frac{i\\pi}{2}}, & \\text{for } \\omega > 0. \\end{cases} Therefore, has the effect of shifting the phase of the negative frequency components of by +90° ( radians) and the phase of the positive frequency components by −90°, and has the effect of restoring the positive frequency components while shifting the negative frequency ones an additional +90°, resulting in their negation (i.e., a multiplication by −1). When the Hilbert transform is applied twice, the phase of the negative and positive frequency components of are respectively shifted by +180° and −180°, which are equivalent amounts. The signal is negated; i.e., , because \\bigl(\\sigma_\\operatorname{H}(\\omega)\\bigr)^2 = e^{\\pm i\\pi} = -1 \\quad \\text{for } \\omega eq 0 . == Table of selected Hilbert transforms == In the following table, the frequency parameter \\omega is real. {| class=\"wikitable\" |- ! Signal u(t) ! Hilbert transformSome authors (e.g., Bracewell) use our as their definition of the forward transform. A consequence is that the right column of this table would be negated. \\operatorname{H}(u)(t) |- | align=\"center\"| \\sin(\\omega t) The Hilbert transform of the sin and cos functions can be defined by taking the principal value of the integral at infinity. This definition agrees with the result of defining the Hilbert transform distributionally. || align=\"center\"| \\begin{array}{lll} \\sin\\left(\\omega t - \\tfrac{\\pi}{2}\\right), \\quad \\omega > 0\\\\\\ \\sin\\left(\\omega t + \\tfrac{\\pi}{2}\\right), \\quad \\omega < 0 \\end{array} |- | align=\"center\"| \\cos(\\omega t) || align=\"center\"| \\begin{array}{lll} \\cos\\left(\\omega t - \\tfrac{\\pi}{2}\\right), \\quad \\omega > 0\\\\\\ \\cos\\left(\\omega t + \\tfrac{\\pi}{2}\\right), \\quad \\omega < 0 \\end{array} |- | align=\"center\"| e^{i \\omega t} || align=\"center\"| \\begin{array}{lll} e^{i\\left(\\omega t - \\tfrac{\\pi}{2}\\right)}, \\quad \\omega > 0\\\\\\ e^{i\\left(\\omega t + \\tfrac{\\pi}{2}\\right)}, \\quad \\omega < 0 \\end{array} |- | align=\"center\"| e^{-i \\omega t} || align=\"center\"| \\begin{array}{lll} e^{-i\\left(\\omega t - \\tfrac{\\pi}{2}\\right)}, \\quad \\omega > 0\\\\\\ e^{-i\\left(\\omega t + \\tfrac{\\pi}{2}\\right)}, \\quad \\omega < 0 \\end{array} |- | align=\"center\"| 1 \\over t^2 + 1 || align=\"center\"| t \\over t^2 + 1 |- | align=\"center\"| e^{-t^2} || align=\"center\"| \\frac{2}{\\sqrt{\\pi\\,}} F(t) (see Dawson function) |- | align=\"center\"| Sinc function \\sin(t) \\over t || align=\"center\"| 1 - \\cos(t)\\over t |- | align=\"center\"| Dirac delta function \\delta(t) || align=\"center\"| {1 \\over \\pi t} |- | align=\"center\"| Characteristic Function \\chi_{[a,b]}(t) || align=\"center\"| { \\frac{1}{\\,\\pi\\,}\\ln \\left\\vert \\frac{t - a}{t - b}\\right\\vert } |} Notes An extensive table of Hilbert transforms is available. Note that the Hilbert transform of a constant is zero. ==Domain of definition== It is by no means obvious that the Hilbert transform is well- defined at all, as the improper integral defining it must converge in a suitable sense. However, the Hilbert transform is well-defined for a broad class of functions, namely those in L^p(\\mathbb{R}) for . More precisely, if is in L^p(\\mathbb{R}) for , then the limit defining the improper integral \\operatorname{H}(u)(t) = -\\frac{1}{\\pi} \\lim_{\\varepsilon \\to 0} \\int_\\varepsilon^\\infty \\frac{u(t + \\tau) - u(t - \\tau)}{\\tau}\\,d\\tau exists for almost every . The limit function is also in L^p(\\mathbb{R}) and is in fact the limit in the mean of the improper integral as well. That is, -\\frac{1}{\\pi} \\int_\\varepsilon^\\infty \\frac{u(t + \\tau) - u(t - \\tau)}{\\tau}\\,\\mathrm{d}\\tau \\to \\operatorname{H}(u)(t) as in the norm, as well as pointwise almost everywhere, by the Titchmarsh theorem. In the case , the Hilbert transform still converges pointwise almost everywhere, but may itself fail to be integrable, even locally. In particular, convergence in the mean does not in general happen in this case. The Hilbert transform of an function does converge, however, in -weak, and the Hilbert transform is a bounded operator from to . (In particular, since the Hilbert transform is also a multiplier operator on , Marcinkiewicz interpolation and a duality argument furnishes an alternative proof that is bounded on .) == Properties == ===Boundedness=== If , then the Hilbert transform on L^p(\\mathbb{R}) is a bounded linear operator, meaning that there exists a constant such that \\left\\|\\operatorname{H}u\\right\\|_p \\le C_p \\left\\|u\\right\\|_p for all This theorem is due to ; see also . The best constant C_p is given byThis result is due to ; see also . C_p = \\begin{cases} \\tan \\frac{\\pi}{2p} & \\text{for} ~ 1 < p \\leq 2\\\\\\ \\cot \\frac{\\pi}{2p} & \\text{for} ~ 2 < p < \\infty \\end{cases} An easy way to find the best C_p for p being a power of 2 is through the so- called Cotlar's identity that (\\operatorname{H}f)^2 =f^2 +2\\operatorname{H}(f\\operatorname{H}f) for all real valued . The same best constants hold for the periodic Hilbert transform. The boundedness of the Hilbert transform implies the L^p(\\mathbb{R}) convergence of the symmetric partial sum operator S_R f = \\int_{-R}^R \\hat{f}(\\xi) e^{2\\pi i x\\xi} \\, \\mathrm{d}\\xi to in See for example . ===Anti-self adjointness=== The Hilbert transform is an anti-self adjoint operator relative to the duality pairing between L^p(\\mathbb{R}) and the dual space where and are Hölder conjugates and . Symbolically, \\langle \\operatorname{H} u, v \\rangle = \\langle u, -\\operatorname{H} v \\rangle for u \\isin L^p(\\mathbb{R}) and ===Inverse transform=== The Hilbert transform is an anti-involution, meaning that \\operatorname{H}\\bigl(\\operatorname{H}\\left(u\\right)\\bigr) = -u provided each transform is well-defined. Since preserves the space this implies in particular that the Hilbert transform is invertible on and that \\operatorname{H}^{-1} = -\\operatorname{H} ===Complex structure=== Because (\"\" is the identity operator) on the real Banach space of real-valued functions in the Hilbert transform defines a linear complex structure on this Banach space. In particular, when , the Hilbert transform gives the Hilbert space of real- valued functions in L^2(\\mathbb{R}) the structure of a complex Hilbert space. The (complex) eigenstates of the Hilbert transform admit representations as holomorphic functions in the upper and lower half-planes in the Hardy space by the Paley–Wiener theorem. ===Differentiation=== Formally, the derivative of the Hilbert transform is the Hilbert transform of the derivative, i.e. these two linear operators commute: \\operatorname{H}\\left(\\frac{ \\mathrm{d}u}{\\mathrm{d}t}\\right) = \\frac{\\mathrm d}{\\mathrm{d}t}\\operatorname{H}(u) Iterating this identity, \\operatorname{H}\\left(\\frac{\\mathrm{d}^ku}{\\mathrm{d}t^k}\\right) = \\frac{\\mathrm{d}^k}{\\mathrm{d}t^k}\\operatorname{H}(u) This is rigorously true as stated provided and its first derivatives belong to One can check this easily in the frequency domain, where differentiation becomes multiplication by . ===Convolutions=== The Hilbert transform can formally be realized as a convolution with the tempered distribution h(t) = \\operatorname{p.v.} \\frac{1}{ \\pi \\, t } Thus formally, \\operatorname{H}(u) = h*u However, a priori this may only be defined for a distribution of compact support. It is possible to work somewhat rigorously with this since compactly supported functions (which are distributions a fortiori) are dense in . Alternatively, one may use the fact that h(t) is the distributional derivative of the function ; to wit \\operatorname{H}(u)(t) = \\frac{\\mathrm{d}}{\\mathrm{d}t}\\left(\\frac{1}{\\pi} \\left(u*\\log\\bigl|\\cdot\\bigr|\\right)(t)\\right) For most operational purposes the Hilbert transform can be treated as a convolution. For example, in a formal sense, the Hilbert transform of a convolution is the convolution of the Hilbert transform applied on only one of either of the factors: \\operatorname{H}(u*v) = \\operatorname{H}(u)*v = u*\\operatorname{H}(v) This is rigorously true if and are compactly supported distributions since, in that case, h*(u*v) = (h*u)*v = u*(h*v) By passing to an appropriate limit, it is thus also true if and provided that 1 < \\frac{1}{p} + \\frac{1}{q} from a theorem due to Titchmarsh. ===Invariance=== The Hilbert transform has the following invariance properties on L^2(\\mathbb{R}). * It commutes with translations. That is, it commutes with the operators for all in \\mathbb{R}. * It commutes with positive dilations. That is it commutes with the operators for all . * It anticommutes with the reflection . Up to a multiplicative constant, the Hilbert transform is the only bounded operator on 2 with these properties. In fact there is a wider set of operators that commute with the Hilbert transform. The group \\text{SL}(2,\\mathbb{R}) acts by unitary operators on the space L^2(\\mathbb{R}) by the formula \\operatorname{U}_{g}^{-1} f(x) = \\frac{1}{ c x + d } \\, f \\left( \\frac{ ax + b }{ cx + d } \\right) \\,,\\qquad g = \\begin{bmatrix} a & b \\\\\\ c & d \\end{bmatrix} ~,\\qquad \\text{ for }~ a d - b c = \\pm 1 . This unitary representation is an example of a principal series representation of ~\\text{SL}(2,\\mathbb{R})~. In this case it is reducible, splitting as the orthogonal sum of two invariant subspaces, Hardy space H^2(\\mathbb{R}) and its conjugate. These are the spaces of boundary values of holomorphic functions on the upper and lower halfplanes. H^2(\\mathbb{R}) and its conjugate consist of exactly those functions with Fourier transforms vanishing on the negative and positive parts of the real axis respectively. Since the Hilbert transform is equal to , with being the orthogonal projection from L^2(\\mathbb{R}) onto \\operatorname{H}^2(\\mathbb{R}), and the identity operator, it follows that \\operatorname{H}^2(\\mathbb{R}) and its orthogonal are eigenspaces of for the eigenvalues . In other words, commutes with the operators . The restrictions of the operators to \\operatorname{H}^2(\\mathbb{R}) and its conjugate give irreducible representations of \\text{SL}(2,\\mathbb{R}) – the so-called limit of discrete series representations.See , , and . ==Extending the domain of definition== ===Hilbert transform of distributions=== It is further possible to extend the Hilbert transform to certain spaces of distributions . Since the Hilbert transform commutes with differentiation, and is a bounded operator on , restricts to give a continuous transform on the inverse limit of Sobolev spaces: \\mathcal{D}_{L^p} = \\underset{n \\to \\infty}{\\underset{\\longleftarrow}{\\lim}} W^{n,p}(\\mathbb{R}) The Hilbert transform can then be defined on the dual space of \\mathcal{D}_{L^p}, denoted \\mathcal{D}_{L^p}', consisting of distributions. This is accomplished by the duality pairing: For define: \\operatorname{H}(u)\\in \\mathcal{D}'_{L^p} = \\langle \\operatorname{H}u, v \\rangle \\ \\triangleq \\ \\langle u, -\\operatorname{H}v\\rangle,\\ \\text{for all} \\ v\\in\\mathcal{D}_{L^p} . It is possible to define the Hilbert transform on the space of tempered distributions as well by an approach due to Gel'fand and Shilov, but considerably more care is needed because of the singularity in the integral. === Hilbert transform of bounded functions === The Hilbert transform can be defined for functions in L^\\infty (\\mathbb{R}) as well, but it requires some modifications and caveats. Properly understood, the Hilbert transform maps L^\\infty (\\mathbb{R}) to the Banach space of bounded mean oscillation (BMO) classes. Interpreted naïvely, the Hilbert transform of a bounded function is clearly ill-defined. For instance, with , the integral defining diverges almost everywhere to . To alleviate such difficulties, the Hilbert transform of an function is therefore defined by the following regularized form of the integral \\operatorname{H}(u)(t) = \\operatorname{p.v.} \\int_{-\\infty}^\\infty u(\\tau)\\left\\\\{h(t - \\tau)- h_0(-\\tau)\\right\\\\} \\, \\mathrm{d}\\tau where as above and h_0(x) = \\begin{cases} 0 & \\text{for} ~ |x| < 1 \\\\\\ \\frac{1}{\\pi \\, x} & \\text{for} ~ |x| \\ge 1 \\end{cases} The modified transform agrees with the original transform on functions of compact support from a general result by Calderón and Zygmund.; see . Furthermore, the resulting integral converges pointwise almost everywhere, and with respect to the BMO norm, to a function of bounded mean oscillation. A deep result of Fefferman's work; is that a function is of bounded mean oscillation if and only if it has the form for some ==Conjugate functions== The Hilbert transform can be understood in terms of a pair of functions and such that the function F(x) = f(x) + i\\,g(x) is the boundary value of a holomorphic function in the upper half-plane. Under these circumstances, if and are sufficiently integrable, then one is the Hilbert transform of the other. Suppose that f \\isin L^p(\\mathbb{R}). Then, by the theory of the Poisson integral, admits a unique harmonic extension into the upper half-plane, and this extension is given by u(x + iy) = u(x, y) = \\frac{1}{\\pi} \\int_{-\\infty}^\\infty f(s)\\;\\frac{y}{(x - s)^2 + y^2} \\; \\mathrm{d}s which is the convolution of with the Poisson kernel P(x, y) = \\frac{ y }{ \\pi\\, \\left( x^2 + y^2 \\right) } Furthermore, there is a unique harmonic function defined in the upper half-plane such that is holomorphic and \\lim_{y \\to \\infty} v\\,(x + i\\,y) = 0 This harmonic function is obtained from by taking a convolution with the conjugate Poisson kernel Q(x, y) = \\frac{ x }{ \\pi\\, \\left(x^2 + y^2\\right) } . Thus v(x, y) = \\frac{1}{\\pi}\\int_{-\\infty}^\\infty f(s)\\;\\frac{x - s}{\\,(x - s)^2 + y^2\\,}\\;\\mathrm{d}s . Indeed, the real and imaginary parts of the Cauchy kernel are \\frac{i}{\\pi\\,z} = P(x, y) + i\\,Q(x, y) so that is holomorphic by Cauchy's integral formula. The function obtained from in this way is called the harmonic conjugate of . The (non-tangential) boundary limit of as is the Hilbert transform of . Thus, succinctly, \\operatorname{H}(f) = \\lim_{y \\to 0} Q(-, y) \\star f === Titchmarsh's theorem === Titchmarsh's theorem (named for E. C. Titchmarsh who included it in his 1937 work) makes precise the relationship between the boundary values of holomorphic functions in the upper half-plane and the Hilbert transform. It gives necessary and sufficient conditions for a complex-valued square-integrable function on the real line to be the boundary value of a function in the Hardy space of holomorphic functions in the upper half-plane . The theorem states that the following conditions for a complex-valued square-integrable function F : \\mathbb{R} \\to \\mathbb{C} are equivalent: * is the limit as of a holomorphic function in the upper half-plane such that \\int_{-\\infty}^\\infty |F(x + i\\,y)|^2\\;\\mathrm{d}x < K * The real and imaginary parts of are Hilbert transforms of each other. * The Fourier transform \\mathcal{F}(F)(x) vanishes for . A weaker result is true for functions of class for . Specifically, if is a holomorphic function such that \\int_{-\\infty}^\\infty |F(x + i\\,y)|^p\\;\\mathrm{d}x < K for all , then there is a complex-valued function in L^p(\\mathbb{R}) such that in the norm as (as well as holding pointwise almost everywhere). Furthermore, F(x) = f(x) - i\\,g(x) where is a real-valued function in L^p(\\mathbb{R}) and is the Hilbert transform (of class ) of . This is not true in the case . In fact, the Hilbert transform of an function need not converge in the mean to another function. Nevertheless, the Hilbert transform of does converge almost everywhere to a finite function such that \\int_{-\\infty}^\\infty \\frac{ |g(x)|^p }{ 1 + x^2 } \\; \\mathrm{d}x < \\infty This result is directly analogous to one by Andrey Kolmogorov for Hardy functions in the disc. Although usually called Titchmarsh's theorem, the result aggregates much work of others, including Hardy, Paley and Wiener (see Paley–Wiener theorem), as well as work by Riesz, Hille, and Tamarkinsee . === Riemann–Hilbert problem === One form of the Riemann–Hilbert problem seeks to identify pairs of functions and such that is holomorphic on the upper half-plane and is holomorphic on the lower half- plane, such that for along the real axis, F_{+}(x) - F_{-}(x) = f(x) where is some given real-valued function of The left-hand side of this equation may be understood either as the difference of the limits of from the appropriate half-planes, or as a hyperfunction distribution. Two functions of this form are a solution of the Riemann–Hilbert problem. Formally, if solve the Riemann–Hilbert problem f(x) = F_{+}(x) - F_{-}(x) then the Hilbert transform of is given by H(f)(x) = -i \\bigl( F_{+}(x) + F_{-}(x) \\bigr) . == Hilbert transform on the circle == For a periodic function the circular Hilbert transform is defined: \\tilde f(x) \\triangleq \\frac{1}{ 2\\pi } \\operatorname{p.v.} \\int_0^{2\\pi} f(t)\\,\\cot\\left(\\frac{ x - t }{2}\\right)\\,\\mathrm{d}t The circular Hilbert transform is used in giving a characterization of Hardy space and in the study of the conjugate function in Fourier series. The kernel, \\cot\\left(\\frac{ x - t }{2}\\right) is known as the Hilbert kernel since it was in this form the Hilbert transform was originally studied. The Hilbert kernel (for the circular Hilbert transform) can be obtained by making the Cauchy kernel periodic. More precisely, for \\frac{1}{\\,2\\,}\\cot\\left(\\frac{x}{2}\\right) = \\frac{1}{x} + \\sum_{n=1}^\\infty \\left(\\frac{1}{x + 2n\\pi} + \\frac{1}{\\,x - 2n\\pi\\,} \\right) Many results about the circular Hilbert transform may be derived from the corresponding results for the Hilbert transform from this correspondence. Another more direct connection is provided by the Cayley transform , which carries the real line onto the circle and the upper half plane onto the unit disk. It induces a unitary map U\\,f(x) = \\frac{1}{(x + i)\\,\\sqrt{\\pi}} \\, f\\left(C\\left(x\\right)\\right) of onto L^2 (\\mathbb{R}). The operator carries the Hardy space onto the Hardy space H^2(\\mathbb{R}). == Hilbert transform in signal processing == === Bedrosian's theorem === Bedrosian's theorem states that the Hilbert transform of the product of a low-pass and a high-pass signal with non-overlapping spectra is given by the product of the low-pass signal and the Hilbert transform of the high-pass signal, or \\operatorname{H}\\left(f_\\text{LP}(t)\\cdot f_\\text{HP}(t)\\right) = f_\\text{LP}(t)\\cdot \\operatorname{H}\\left(f_\\text{HP}(t)\\right), where and are the low- and high-pass signals respectively. A category of communication signals to which this applies is called the narrowband signal model. A member of that category is amplitude modulation of a high-frequency sinusoidal \"carrier\": u(t) = u_m(t) \\cdot \\cos(\\omega t + \\phi), where is the narrow bandwidth \"message\" waveform, such as voice or music. Then by Bedrosian's theorem: \\operatorname{H}(u)(t) = u_m(t) \\cdot \\sin(\\omega t + \\phi). === Analytic representation === A specific type of conjugate function is: u_a(t) \\triangleq u(t) + i\\cdot H(u)(t), known as the analytic representation of u(t). The name reflects its mathematical tractability, due largely to Euler's formula. Applying Bedrosian's theorem to the narrowband model, the analytic representation is: A Fourier transform property indicates that this complex heterodyne operation can shift all the negative frequency components of above 0 Hz. In that case, the imaginary part of the result is a Hilbert transform of the real part. This is an indirect way to produce Hilbert transforms. === Angle (phase/frequency) modulation === The form: u(t) = A \\cdot \\cos(\\omega t + \\phi_m(t)) is called angle modulation, which includes both phase modulation and frequency modulation. The instantaneous frequency is \\omega + \\phi_m^\\prime(t). For sufficiently large , compared to \\operatorname{H}(u)(t) \\approx A \\cdot \\sin(\\omega t + \\phi_m(t)) and: u_a(t) \\approx A \\cdot e^{i(\\omega t + \\phi_m(t))}. === Single sideband modulation (SSB) === When in is also an analytic representation (of a message waveform), that is: u_m(t) = m(t) + i \\cdot \\widehat{m}(t) the result is single-sideband modulation: u_a(t) = (m(t) + i \\cdot \\widehat{m}(t)) \\cdot e^{i(\\omega t + \\phi)} whose transmitted component is: \\begin{align} u(t) &= \\operatorname{Re}\\\\{u_a(t)\\\\}\\\\\\ &= m(t)\\cdot \\cos(\\omega t + \\phi) - \\widehat{m}(t)\\cdot \\sin(\\omega t + \\phi) \\end{align} ===Causality=== The function h(t) = 1/(\\pi t) presents two challenges to practical implementation as a convolution: * Its duration is infinite (technically infinite support). A finite length approximation must be used instead. But windowing the length also reduces the effective frequency range of the transform. The shorter the window, the greater the losses at low and high frequencies. See also quadrature filter. * It is a non-causal filter. So a delayed version, h(t-\\tau), is required. The corresponding output is subsequently delayed by \\tau. When creating the imaginary part of an analytic signal, the source (real part) must be delayed by the equivalent amount. == Discrete Hilbert transform == thumb|400px|right|Figure 1: Filter whose frequency response is bandlimited to about 95% of the Nyquist frequency thumb|400px|right|Figure 2: Hilbert transform filter with a highpass frequency response thumb|400px|right|Figure 3\\. thumb|400px|right|Figure 4\\. The Hilbert transform of is . This figure shows and two approximate Hilbert transforms computed by the MATLAB library function, thumb|400px|right|Figure 5\\. Discrete Hilbert transforms of a cosine function, using piecewise convolution For a discrete function, with discrete- time Fourier transform (DTFT), and discrete Hilbert transform the DTFT of \\hat u[n] in the region is given by: \\operatorname{DTFT} (\\hat u) = U(\\omega)\\cdot (-i\\cdot \\sgn(\\omega)). The inverse DTFT, using the convolution theorem, is: \\begin{align} \\hat u[n] &= {\\scriptstyle \\mathrm{DTFT}^{-1}} (U(\\omega))\\ *\\ {\\scriptstyle \\mathrm{DTFT}^{-1}} (-i\\cdot \\sgn(\\omega))\\\\\\ &= u[n]\\ *\\ \\frac{1}{2 \\pi}\\int_{-\\pi}^{\\pi} (-i\\cdot \\sgn(\\omega))\\cdot e^{i \\omega n} \\,\\mathrm{d}\\omega\\\\\\ &= u[n]\\ *\\ \\underbrace{\\frac{1}{2 \\pi}\\left[\\int_{-\\pi}^0 i\\cdot e^{i \\omega n} \\,\\mathrm{d}\\omega - \\int_0^\\pi i\\cdot e^{i \\omega n} \\,\\mathrm{d}\\omega \\right]}_{h[n]}, \\end{align} where h[n]\\ \\triangleq \\ \\begin{cases} 0, & \\text{for }n\\text{ even}\\\\\\ \\frac 2 {\\pi n} & \\text{for }n\\text{ odd}, \\end{cases} which is an infinite impulse response (IIR). When the convolution is performed numerically, an FIR approximation is substituted for , as shown in Figure 1\\. An FIR filter with an odd number of anti-symmetric coefficients is called Type III, which inherently exhibits responses of zero magnitude at frequencies 0 and Nyquist, resulting in this case in a bandpass filter shape. A Type IV design (even number of anti-symmetric coefficients) is shown in Figure 2\\. Since the magnitude response at the Nyquist frequency does not drop out, it approximates an ideal Hilbert transformer a little better than the odd-tap filter. However * A typical (i.e. properly filtered and sampled) sequence has no useful components at the Nyquist frequency. * The Type IV impulse response requires a sample shift in the sequence. That causes the zero-valued coefficients to become non-zero, as seen in Figure 2\\. So a Type III design is potentially twice as efficient as Type IV. * The group delay of a Type III design is an integer number of samples, which facilitates aligning \\hat u[n] with u[n], to create an analytic signal. The group delay of Type IV is halfway between two samples. The MATLAB function, , convolves a u[n] sequence with the periodic summation: :h_N[n]\\ \\triangleq \\sum_{m=-\\infty}^\\infty h[n - mN] and returns one cycle ( samples) of the periodic result in the imaginary part of a complex-valued output sequence. The convolution is implemented in the frequency domain as the product of the array {\\scriptstyle \\mathrm{DFT}} \\left(u[n]\\right) with samples of the distribution (whose real and imaginary components are all just 0 or ). Figure 3 compares a half-cycle of with an equivalent length portion of . Given an FIR approximation for h[n], denoted by \\tilde{h}[n], substituting {\\scriptstyle\\mathrm{DFT}} \\left(\\tilde{h}[n]\\right) for the samples results in an FIR version of the convolution. The real part of the output sequence is the original input sequence, so that the complex output is an analytic representation of . When the input is a segment of a pure cosine, the resulting convolution for two different values of is depicted in Figure 4 (red and blue plots). Edge effects prevent the result from being a pure sine function (green plot). Since is not an FIR sequence, the theoretical extent of the effects is the entire output sequence. But the differences from a sine function diminish with distance from the edges. Parameter is the output sequence length. If it exceeds the length of the input sequence, the input is modified by appending zero-valued elements. In most cases, that reduces the magnitude of the differences. But their duration is dominated by the inherent rise and fall times of the impulse response. An appreciation for the edge effects is important when a method called overlap-save is used to perform the convolution on a long sequence. Segments of length are convolved with the periodic function: \\tilde{h}_N[n]\\ \\triangleq \\sum_{m=-\\infty}^\\infty \\tilde{h}[n - mN]. When the duration of non-zero values of \\tilde{h}[n] is M < N, the output sequence includes samples of \\hat u. outputs are discarded from each block of , and the input blocks are overlapped by that amount to prevent gaps. Figure 5 is an example of using both the IIR hilbert(·) function and the FIR approximation. In the example, a sine function is created by computing the Discrete Hilbert transform of a cosine function, which was processed in four overlapping segments, and pieced back together. As the FIR result (blue) shows, the distortions apparent in the IIR result (red) are not caused by the difference between and (green and red in Figure 3). The fact that is tapered (windowed) is actually helpful in this context. The real problem is that it's not windowed enough. Effectively, , whereas the overlap-save method needs . == Number-theoretic Hilbert transform == The number theoretic Hilbert transform is an extension of the discrete Hilbert transform to integers modulo an appropriate prime number. In this it follows the generalization of discrete Fourier transform to number theoretic transforms. The number theoretic Hilbert transform can be used to generate sets of orthogonal discrete sequences. == See also == * Analytic signal * Harmonic conjugate * Hilbert spectroscopy * Hilbert transform in the complex plane * Hilbert–Huang transform * Kramers–Kronig relation * Riesz transform * Single-sideband signal * Singular integral operators of convolution type == Notes == == Page citations == == References == * * * * * * * * * * * * * * * * * ; also http://www.fuchs-braun.com/media/d9140c7b3d5004fbffff8007fffffff0.pdf * * * * * * * * * * * * * * * * ; also https://www.dsprelated.com/freebooks/mdft/Analytic_Signals_Hilbert_Transform.html * * * * * * == Further reading == * * * * * == External links == * Derivation of the boundedness of the Hilbert transform * Mathworld Hilbert transform — Contains a table of transforms * * an entry level introduction to Hilbert transformation. Category:Harmonic functions Category:Integral transforms Category:Signal processing Category:Singular integrals",
 "title": "Hilbert transform"
}